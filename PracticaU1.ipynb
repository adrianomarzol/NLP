{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Práctica de la Unidad 1"
      ],
      "metadata": {
        "id": "Cm4N9_X_Orgz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Ejercicio 1**:\n",
        "\n",
        "**Objetivo**: Desarrollar un buscador flexible en Python que permita encontrar frases relevantes en un conjunto de textos en español, utilizando técnicas de procesamiento de lenguaje natural.\n",
        "\n",
        "1.   Desarrollar una función `procesar_texto(texto)` que dado un texto de entrada, permita normalizar, eliminar stopwords, y lematizar.\n",
        "2.   Escribir una lista de 10 frases, que utilizaremos para realizar búsquedas.\n",
        "3.   Escribir una función que permita, a partir de una frase, realizar una búsqueda sobre las 10 frases, comparando con las frases procesadas con la función del punto 1. En la comparación, calcularemos un puntaje de acuerdo a las palabras en común, sin importar el orden.\n",
        "4.   Mostrar un ranking descendente de las frases según el puntaje.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FKIY4ItMO4zS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download es_core_news_sm"
      ],
      "metadata": {
        "id": "w9mYuWDPSKyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "Xl5By_KFdoJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "import es_core_news_sm\n",
        "\n",
        "import PyPDF2\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "YNYef2FrQY9m"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lista de stopwords en español.\n",
        "stopwords_es = [\n",
        "    'de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un',\n",
        "    'para', 'con', 'no', 'una', 'su', 'al', 'lo', 'como', 'más', 'pero', 'sus', 'le',\n",
        "    'ya', 'o', 'este', 'sí', 'porque', 'esta', 'entre', 'cuando', 'muy', 'sin',\n",
        "    'sobre', 'también', 'me', 'hasta', 'hay', 'donde', 'quien', 'desde', 'todo',\n",
        "    'nos', 'durante', 'todos', 'uno', 'les', 'ni', 'contra', 'otros', 'ese', 'eso',\n",
        "    'ante', 'ellos', 'e', 'esto', 'mí', 'antes', 'algunos', 'qué', 'unos', 'yo',\n",
        "    'otro', 'otras', 'otra', 'él', 'tanto', 'esa', 'estos', 'mucho', 'quienes',\n",
        "    'nada', 'muchos', 'cual', 'poco', 'ella', 'estar', 'estas', 'algunas', 'algo',\n",
        "    'nosotros', 'mi', 'mis', 'tú', 'te', 'ti', 'tu', 'tus', 'ellas', 'nosotras',\n",
        "    'vosotros', 'vosotras', 'os', 'mío', 'mía', 'míos', 'mías', 'tuyo', 'tuya',\n",
        "    'tuyos', 'tuyas', 'suyo', 'suya', 'suyos', 'suyas', 'nuestro', 'nuestra',\n",
        "    'nuestros', 'nuestras', 'vuestro', 'vuestra', 'vuestros', 'vuestras', 'es'\n",
        "]"
      ],
      "metadata": {
        "id": "UPGZ1-SnRkUF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remover_acentos(entrada_texto):\n",
        "    nfkd_form = unicodedata.normalize('NFKD', entrada_texto)\n",
        "    return ''.join([c for c in nfkd_form if not unicodedata.combining(c)])"
      ],
      "metadata": {
        "id": "DkeIikAtQxt3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eliminar_stopwords(texto):\n",
        "    #Separar el texto en palabras.\n",
        "    palabras = texto.split()\n",
        "    # Filtrar las palabras para eliminar las stopwords.\n",
        "    palabras_filtradas = [palabra for palabra in palabras if palabra.lower() not in stopwords_es]\n",
        "    # Unir las palabras filtradas en una cadena y la retornamos.\n",
        "    return ' '.join(palabras_filtradas)"
      ],
      "metadata": {
        "id": "CGH92NKIRqWJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargar el modelo de lenguaje español\n",
        "nlp = es_core_news_sm.load()\n",
        "\n",
        "def lematizar_texto_es(texto):\n",
        "    doc = nlp(texto)\n",
        "    lemmas = [tok.lemma_.lower() for tok in doc]\n",
        "    return ' '.join(lemmas)"
      ],
      "metadata": {
        "id": "wJ8AipZZSUGD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def procesar_texto(texto):\n",
        "    #Transformar el texto a minúsculas.\n",
        "    texto = texto.lower()\n",
        "    #Eliminar puntuación.\n",
        "    texto = re.sub(r'[^\\w\\s]', '', texto)\n",
        "    #Eliminar acentos.\n",
        "    texto = remover_acentos(texto)\n",
        "    #Eliminar stopwords.\n",
        "    texto = eliminar_stopwords(texto)\n",
        "    #Lematizar texto.\n",
        "    texto = lematizar_texto_es(texto)\n",
        "\n",
        "    return texto"
      ],
      "metadata": {
        "id": "2Fl71nKqOz-y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lista de frases para realizar la búsqueda.\n",
        "frases = ['¡La música, sin duda, es el lenguaje universal del alma!','Después de un día agotador... ¿qué mejor que un poco de jazz relajante?',\n",
        "          'Beethoven, ese genio alemán, compuso –entre otras obras maestras– la Novena Sinfonía.','Mi playlist es una locura: rock, salsa, electrónica... ¡y hasta algo de K-pop!',\n",
        "          'No puedo, simplemente no puedo, concentrarme sin música instrumental de fondo.','\"Esa canción\", dijo entre lágrimas, \"me recuerda todo lo que perdí...\"',\n",
        "          '¿Sabes qué es lo más curioso?”, preguntó él, mientras el piano sonaba de fondo, “esa melodía... me hace sentir como si flotara.','Toco la guitarra desde los quince años; al principio fue difícil, ahora es pasión.',\n",
        "          '¡Hoy, por fin!, se lanza el nuevo álbum de mi banda favorita: ¡no puedo esperar!','Las notas altas del violín... suaves, agudas, casi etéreas... me erizan la piel.']"
      ],
      "metadata": {
        "id": "cNhN9iIwThT7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def comparar_frase(nueva_frase, lista_frases):\n",
        "    puntuaciones = []\n",
        "    nueva_frase_procesada = procesar_texto(nueva_frase)\n",
        "\n",
        "    for frase in lista_frases:\n",
        "        frase_procesada = procesar_texto(frase)\n",
        "        puntuacion = 0\n",
        "        for palabra in nueva_frase_procesada.split():\n",
        "            if palabra in frase_procesada.split():\n",
        "                puntuacion = puntuacion + 1\n",
        "        puntuaciones.append([puntuacion, frase])\n",
        "\n",
        "    puntuaciones = sorted(puntuaciones, key=lambda x: x[0], reverse=True)\n",
        "\n",
        "    return puntuaciones"
      ],
      "metadata": {
        "id": "3M4HJ2iiUmis"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparaciones = comparar_frase('La melodía de esa canción, tocada en guitarra y piano al mismo tiempo, es simplemente hipnótica', frases)\n",
        "\n",
        "for puntuacion, frase in comparaciones:\n",
        "    print(f'Puntuación: {puntuacion}, Frase: {frase}')"
      ],
      "metadata": {
        "id": "trxqjcwSWZvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Ejercicio 2**:\n",
        "\n",
        "**Objetivo**: Desarrollar un programa en Python que permita al usuario buscar expresiones en lunfardo, basándose en descripciones de conceptos o acciones. El sistema deberá comparar la descripción del usuario con las definiciones de un diccionario de lunfardo y devolver las tres palabras cuyas definiciones sean más parecidas a la descripción ingresada.\n",
        "\n",
        "**Preparación de Datos**:\n",
        "\n",
        "Extraiga el texto de un diccionario de lunfardo desde un recurso en línea (enlace proporcionado), y organícelo en una tabla de dos columnas:\n",
        "\n",
        "- Columna 1: Palabra en lunfardo.\n",
        "- Columna 2: Definición de la palabra.\n",
        "\n",
        "**Desarrollo del Programa**:\n",
        "\n",
        "Implemente una función `buscar_en_lunfardo(descripcion)` que realice de  las siguientes tareas las que crea útiles:\n",
        "\n",
        "- Normalización: Convertir la descripción a minúsculas y eliminar caracteres no alfanuméricos.\n",
        "- Eliminación de stopwords: Remover palabras que no aporten significado relevante, utilizando una lista predefinida de stopwords en español.\n",
        "- Lematización: Reducir las palabras a su forma base o lema, para facilitar la comparación con las definiciones del diccionario.\n",
        "- Tokenización: Dividir la descripción en palabras individuales para su análisis.\n",
        "- Comparación y Conteo:Utilizar técnicas básicas de comparación de texto para identificar las tres definiciones en el diccionario que más se asemejen a la descripción ingresada.\n",
        "\n",
        "**Ejemplo**:\n",
        "\n",
        "Entrada del usuario: \"Persona que engaña a los demás.\"\n",
        "\n",
        "Salida esperada: Podría incluir palabras como \"vivo\", \"avivado\", \"pícaro\", dependiendo de las definiciones disponibles en el diccionario de lunfardo.\n"
      ],
      "metadata": {
        "id": "Ovi_AE0aYkhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Extraer el texto del archivo pdf: Lunfardo.pdf.\n",
        "with open('Lunfardo.pdf', 'rb') as archivo:\n",
        "    #Crear un objeto PdfFileReader\n",
        "    lector = PyPDF2.PdfReader(archivo)\n",
        "\n",
        "    #Inicializar una cadena vacía para almacenar el texto\n",
        "    texto = ''\n",
        "\n",
        "    #Iterar sobre todas las páginas del PDF\n",
        "    for i in range(len(lector.pages)):\n",
        "        #Obtener la página\n",
        "        pagina = lector.pages[i]\n",
        "\n",
        "        #Extraer el texto de la página y lo añade a la cadena de texto\n",
        "        texto += pagina.extract_text ()\n",
        "\n",
        "#Unificar el texto\n",
        "texto = texto.replace('\\n', ' ')\n",
        "\n",
        "#Eliminar encabezados comunes\n",
        "texto = re.sub(r'\\b(LUNFARDO|DICCIONARIO[A-Z]*)\\b', '', texto, flags=re.IGNORECASE)\n",
        "texto = re.sub(r'\\b[A-Z]\\b', '', texto)  # Borra letras solas como \"A\", \"B\" que separan secciones\n",
        "\n",
        "#Expresión regular para encontrar las entradas\n",
        "regex = re.compile(r'([A-ZÁÉÍÓÚÑa-záéíóúñ() ]{2,}?)\\s*:\\s*(.*?)(?=(?:[A-ZÁÉÍÓÚÑa-záéíóúñ() ]{2,}?\\s*:)|$)')\n",
        "\n",
        "resultados = regex.findall(texto)\n",
        "\n",
        "#Crear el DataFrame\n",
        "dic_lunfardo = pd.DataFrame(resultados, columns=['palabra', 'definicion'])\n",
        "\n",
        "#Limpiar texto\n",
        "dic_lunfardo['palabra'] = dic_lunfardo['palabra'].str.strip()\n",
        "dic_lunfardo['definicion'] = dic_lunfardo['definicion'].str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
        "\n",
        "#Eliminar el texto que no corresponde al final del DataFrame.\n",
        "dic_lunfardo = dic_lunfardo.iloc[:-1]\n",
        "dic_lunfardo['definicion'][dic_lunfardo['palabra'] == 'Zurdo'] = 'El que milita en la izquierda política y el que profesa la ideología comunista.'"
      ],
      "metadata": {
        "id": "coZGY6Lhb3fU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def buscar_en_lunfardo(descripcion):\n",
        "    #Aplico funciones para procesar y comparar la frase\n",
        "    descripcion = procesar_texto(descripcion)\n",
        "    comparaciones = comparar_frase(descripcion, dic_lunfardo['definicion'])\n",
        "\n",
        "    #Muestro las palabras que mas se asemejan.\n",
        "    for i in range(0, 3):\n",
        "        print(f\"Palabra {i+1}: {df['palabra'][comparaciones[i][1] == df['definicion']].to_string(index=False)}\")"
      ],
      "metadata": {
        "id": "WWbwnhIXe3nm"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "buscar_en_lunfardo('Persona que engaña a los demás.')"
      ],
      "metadata": {
        "id": "1Y1ArWO3g5qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Ejercicio 3**:\n",
        "\n",
        "**Objetivo**: Desarrollar un programa en Python que permita al usuario buscar expresiones en lunfardo, basándose en descripciones de conceptos o acciones. El sistema deberá comparar la descripción del usuario con las definiciones de un diccionario de lunfardo y devolver las tres palabras cuyas definiciones sean más parecidas a la descripción ingresada.\n",
        "\n",
        "Utilice la técnica que crea más conveniente del a la unidad 2 para mejorar la performance de las respuestas. (Sólo utilice metodologías hasta word2vec).\n",
        "Analice las mejoras de comportamiento del algoritmo de recomendación.\n",
        "\n"
      ],
      "metadata": {
        "id": "Kof14fMtb4al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def buscar_en_lunfardo_tfidf(descripcion, diccionario):\n",
        "\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(diccionario['definicion'])\n",
        "\n",
        "    descripcion_vectorizada = tfidf_vectorizer.transform([descripcion])\n",
        "\n",
        "    similitudes = cosine_similarity(descripcion_vectorizada, tfidf_matrix)[0]\n",
        "\n",
        "    top_indices = np.argsort(similitudes)[-3:][::-1]  # del más similar al menos\n",
        "\n",
        "    print(f\"Frase: {descripcion}\")\n",
        "    print(\"Top 3 palabras más parecidas:\")\n",
        "    for i in top_indices:\n",
        "        palabra = diccionario['palabra'].iloc[i]\n",
        "        similitud = similitudes[i]\n",
        "        print(f\"- {palabra} ({similitud:.2f})\")"
      ],
      "metadata": {
        "id": "mXbKQrzauEDx"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "buscar_en_lunfardo_tfidf('Persona que engaña a los demás.', dic_lunfardo)"
      ],
      "metadata": {
        "id": "d-i6EuD-u5hr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}